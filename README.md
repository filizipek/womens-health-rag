# Women's Health RAG (Ollama + FAISS)

A local-first Retrieval-Augmented Generation (RAG) demo for women's health questions.

- **Retrieval:** SentenceTransformers embeddings + **FAISS**
- **Generation:** **Ollama** (local LLM only — no API keys)
- **Goal:** Given a user complaint, retrieve relevant evidence from a curated corpus and produce an **educational, non-diagnostic** answer with citations.

> ⚠️ This is an educational prototype. It is not medical advice.

---

## What you can do with this repo

- Build a small women's health knowledge base from reliable sources (e.g., NHS, MedlinePlus, open-access PDFs)
- Chunk and index content
- Query it via:
  - a CLI (`retrieve.py`, `answers.py`)
  - a local API + Swagger (`api.py`)

---

## Requirements

- Python **3.10+** (3.12 works)
- Ollama installed (local LLM runtime)
- macOS / Linux (Windows can work but instructions may differ)

Install Python deps:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Ollama setup (required)

This project uses Ollama **only** for generation.

1. Install Ollama: https://ollama.com

2. Pull a model (default used in this repo):

```bash
ollama pull llama3.1:8b
```

3. Start the Ollama server (keep running in a separate terminal):

```bash
ollama serve
```

4. Quick health check:

```bash
curl http://127.0.0.1:11434/api/tags
```

---

## Project structure

```
corpus/
  raw/                         # downloaded PDFs / HTML snapshots (generated)
    A_patient_info/
    B_peer_reviewed/
  text/                        # extracted text (generated)
  chunks/
    chunks.jsonl               # chunk output (generated)
  index/
    faiss.index                # FAISS vector index (generated)
    chunk_meta.jsonl           # metadata aligned with index rows (generated)
  answers/
    answers.jsonl              # model outputs (generated)
  metadata/
    manifest.csv               # your curated source list + tags
    manifest_resolved.csv      # optional (if you resolve DOI access)
    tag_vocab.yaml             # allowed tag vocabulary
    documents.jsonl            # generated by collector
    text_index.jsonl           # generated by extractor
  logs/
    collector_report.json      # collector report (generated)

scripts/
  validate_manifest.py
  resolve_access.py            # optional DOI→OA resolver
  collect.py
  extract_text.py
  chunk.py
  retrieve.py
  answers.py                   # retrieval + Ollama generation
  api.py                       # optional FastAPI wrapper
```

---

## Tagging philosophy

Each doc/chunk can carry structured tags to support filtering:

| Tag | Values |
|-----|--------|
| `tier` | `tier:A_patient_info`, `tier:B_peer_reviewed` |
| `source` | `source:NHS`, `source:MedlinePlus`, `source:Journal`, … |
| `type` | `type:patient_page`, `type:guideline_page`, `type:journal_article`, … |

**Optional tags:**

| Tag | Description |
|-----|-------------|
| `topic:*` | Domain bucket |
| `sx:*` | Symptoms |
| `ctx:*` | Context (e.g. `ctx:pregnant`) |
| `possible:*` | Possible condition label — used carefully |
| `triage:*` | e.g. `triage:emergency`, `triage:see_gp_routine` |

---

## Quick demo (after you have a manifest)

```bash
python3 scripts/validate_manifest.py corpus/metadata/manifest.csv corpus/metadata/tag_vocab.yaml
mkdir -p corpus/logs corpus/text corpus/chunks corpus/index corpus/answers

python3 scripts/collect.py corpus/metadata/manifest.csv corpus/metadata/documents.jsonl corpus/logs/collector_report.json
python3 scripts/extract_text.py corpus/metadata/documents.jsonl corpus/metadata/text_index.jsonl
python3 scripts/chunk.py corpus/metadata/text_index.jsonl corpus/chunks/chunks.jsonl 1000 150
python3 scripts/embed_faiss.py corpus/chunks/chunks.jsonl corpus/index/faiss.index corpus/index/chunk_meta.jsonl

ollama serve  # keep running in another terminal
python3 scripts/answers.py corpus/index/faiss.index corpus/index/chunk_meta.jsonl \
  --query "pelvic pain heavy bleeding painful periods for 3 months" \
  --k 6 \
  --out corpus/answers/answers.jsonl
```

---

## Demo: end-to-end pipeline

### 1) Validate your manifest

Edit:
- `corpus/metadata/manifest.csv`
- `corpus/metadata/tag_vocab.yaml`

Then:

```bash
python3 scripts/validate_manifest.py corpus/metadata/manifest.csv corpus/metadata/tag_vocab.yaml
```

### 2) Collect documents (PDF/HTML snapshots)

```bash
mkdir -p corpus/logs
python3 scripts/collect.py corpus/metadata/manifest.csv corpus/metadata/documents.jsonl corpus/logs/collector_report.json
```

If some links are paywalled DOI URLs, try resolving them (optional):

```bash
python3 scripts/resolve_access.py corpus/metadata/manifest.csv corpus/metadata/manifest_resolved.csv your@email.com
python3 scripts/collect.py corpus/metadata/manifest_resolved.csv corpus/metadata/documents.jsonl corpus/logs/collector_report.json
```

### 3) Extract text

```bash
mkdir -p corpus/text
python3 scripts/extract_text.py corpus/metadata/documents.jsonl corpus/metadata/text_index.jsonl
```

### 4) Chunk text

Baseline "recursive chunking":

```bash
mkdir -p corpus/chunks
python3 scripts/chunk.py corpus/metadata/text_index.jsonl corpus/chunks/chunks.jsonl 1000 150
```

### 5) Embed + build FAISS index

This step creates:
- `corpus/index/faiss.index`
- `corpus/index/chunk_meta.jsonl`

Run:

```bash
mkdir -p corpus/index
python3 scripts/embed_faiss.py \
  corpus/chunks/chunks.jsonl \
  corpus/index/faiss.index \
  corpus/index/chunk_meta.jsonl
```

> **Tip (macOS):** If you hit FAISS installation issues, ensure `faiss-cpu` is installed in your active virtual environment:
> ```bash
> pip install faiss-cpu
> ```

### 6) Retrieval debug

```bash
python3 scripts/retrieve.py corpus/index/faiss.index corpus/index/chunk_meta.jsonl \
  "pelvic pain heavy bleeding painful periods" 8
```

### 7) Generate an answer (RAG + Ollama)

```bash
mkdir -p corpus/answers
python3 scripts/answers.py corpus/index/faiss.index corpus/index/chunk_meta.jsonl \
  --query "pelvic pain heavy bleeding painful periods for 3 months" \
  --k 6 \
  --out corpus/answers/answers.jsonl
```

You should get JSON like:

```json
{
  "answer": "LLM-written but grounded in retrieved snippets",
  "citations": [
    { "url": "...", "chunk_id": "...", "score": 0.87 }
  ],
  "debug": {
    "context": "...",
    "sti_detected": false
  }
}
```

---

## Optional: FastAPI + Swagger

Run:

```bash
touch scripts/__init__.py
python3 -m uvicorn scripts.api:app --reload --port 8000 --host 127.0.0.1
```

Open Swagger UI: http://127.0.0.1:8000/docs

Example POST body:

```json
{ "query": "burning when peeing and unusual discharge", "k": 6 }
```

---

## Configuration (environment variables)

You can tune behavior via env vars:

### Ollama

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_MODEL` | `llama3.1:8b` | Model to use for generation |
| `OLLAMA_URL` | `http://127.0.0.1:11434/api/generate` | Ollama API endpoint |
| `OLLAMA_TIMEOUT_S` | `60` | Request timeout in seconds |
| `OLLAMA_TEMPERATURE` | `0.2` | Sampling temperature |

### Retrieval

| Variable | Default | Description |
|----------|---------|-------------|
| `RAG_MIN_SCORE` | — | Filter weak hits (e.g. `0.40`) |
| `RAG_CANDIDATES` | `80` | Number of candidates to retrieve |
| `RAG_MAX_PER_DOC` | `1` | Max chunks per document |
| `RAG_MAX_PER_SOURCE` | `4` | Max chunks per source |
| `RAG_SUPPRESS_STI_DOC` | `1` | Prevent STI guideline dominance for non-STI queries |

Example:

```bash
export RAG_MIN_SCORE=0.40
export OLLAMA_MODEL=llama3.1:8b
```

---

## Medical safety notes

This is an educational prototype and **must not** be treated as medical advice.

**Recommended safety policy:**

- Prefer Tier A sources for patient-facing phrasing and triage.
- Treat Tier B sources as background evidence; avoid turning them into direct advice.
- The generator should be:
  - non-diagnostic
  - source-cited (URLs + chunk IDs)
  - explicit about uncertainty (`"sources do not specify"`)
  - include urgent-care guidance for severe symptoms

---
